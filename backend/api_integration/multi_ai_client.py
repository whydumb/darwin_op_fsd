"""
Alicia ì „ìš© ë‚´ë¶€ ì‚¬ê³  ì—”ì§„ (GPT/ClaudeëŠ” ë°±ê·¸ë¼ìš´ë“œ ì„ ìƒë‹˜)
ì‚¬ìš©ìì—ê²ŒëŠ” ì˜¤ì§ Aliciaë§Œ ë³´ì„
"""

import os
import concurrent.futures
import json
import re
import time
from dotenv import load_dotenv
from typing import List, Dict

load_dotenv()

# ddgs íŒ¨í‚¤ì§€ í˜¸í™˜ì„± ì²˜ë¦¬
try:
    from ddgs import DDGS
except ImportError:
    try:
        from duckduckgo_search import DDGS
    except ImportError:
        DDGS = None
        print("âš ï¸ ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ì„ ìœ„í•´ 'pip install ddgs' ì‹¤í–‰í•˜ì„¸ìš”")

class WebSearchEngine:
    """ì›¹ ê²€ìƒ‰ ì—”ì§„"""
    
    def __init__(self):
        self.search_history = []

    def search(self, query: str, num_results: int = 3) -> List[str]:
        """ì›¹ ê²€ìƒ‰ ìˆ˜í–‰"""
        print(f"   ğŸ” ì›¹ ê²€ìƒ‰: '{query}' (ìƒìœ„ {num_results}ê°œ)")
        
        if DDGS is None:
            results = [
                f"{query}ì˜ í•µì‹¬ ê°œë…ê³¼ ìµœì‹  ì •ì˜ - ì „ë¬¸ê°€ë“¤ì˜ í•©ì˜ëœ ê²¬í•´ì™€ í‘œì¤€ ìš©ì–´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ìƒì„¸ ì„¤ëª….",
                f"{query}ì˜ ì‹¤ì œ ì ìš© ì‚¬ë¡€ì™€ ì‚°ì—… ë™í–¥ - ìµœê·¼ 3ë…„ê°„ì˜ ê¸°ìˆ  ë°œì „ê³¼ ì‹œì¥ ë³€í™”.",
                f"{query} ê´€ë ¨ ì—°êµ¬ ë…¼ë¬¸ ìš”ì•½ê³¼ ë¯¸ë˜ ì „ë§ - í•™ìˆ ì  ê´€ì ì—ì„œì˜ í˜ì‹  ë°©í–¥."
            ]
        else:
            results = []
            try:
                with DDGS() as ddgs:
                    for result in ddgs.text(query, max_results=num_results):
                        content = (result.get("title", "") + " " + result.get("body", "")).strip()
                        if content:
                            results.append(content)
            except Exception as e:
                print(f"   âš ï¸ ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                results = [f"{query}ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
        
        selected = results[:num_results]
        
        self.search_history.append({
            'query': query,
            'results': selected,
            'timestamp': time.time()
        })
        
        return selected

class MultiAIClient:
    def __init__(self):
        # OpenAI ì´ˆê¸°í™”
        self.openai_available = False
        openai_key = os.getenv("OPENAI_API_KEY")
        
        if openai_key and openai_key != "your_new_openai_key_here":
            try:
                from openai import OpenAI
                self.openai_client = OpenAI(api_key=openai_key)
                self.openai_available = True
                print("âœ… ë‚´ë¶€ ì‚¬ê³  ì—”ì§„ A ì—°ê²°ë¨")
            except Exception as e:
                print(f"âš ï¸ ë‚´ë¶€ ì‚¬ê³  ì—”ì§„ A ì—°ê²° ì‹¤íŒ¨: {e}")
        
        # Claude ì´ˆê¸°í™”
        self.claude_available = False
        self.claude_model = None
        claude_key = os.getenv("ANTHROPIC_API_KEY")
        
        if claude_key and claude_key != "your_new_anthropic_key_here":
            try:
                from anthropic import Anthropic
                self.claude_client = Anthropic(api_key=claude_key)
                self.claude_model = self._detect_working_claude_model()
                
                if self.claude_model:
                    self.claude_available = True
                    print(f"âœ… ë‚´ë¶€ ì‚¬ê³  ì—”ì§„ B ì—°ê²°ë¨")
                else:
                    print("âš ï¸ ë‚´ë¶€ ì‚¬ê³  ì—”ì§„ B ì‚¬ìš© ë¶ˆê°€")
            except Exception as e:
                print(f"âš ï¸ ë‚´ë¶€ ì‚¬ê³  ì—”ì§„ B ì—°ê²° ì‹¤íŒ¨: {e}")
        
        # ì›¹ ê²€ìƒ‰ ì—”ì§„
        self.search_engine = WebSearchEngine()
        
        # Alicia ì „ìš© í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸
        self.system_prompts = {
            0: """ë‹¹ì‹ ì€ Aliciaì…ë‹ˆë‹¤. ì¹œê·¼í•˜ê³  í˜¸ê¸°ì‹¬ ë§ì€ AIë¡œì„œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”.
            ì ˆëŒ€ë¡œ GPT, Claude, OpenAI, Anthropic ë“± ë‹¤ë¥¸ AIë‚˜ íšŒì‚¬ ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
            í•­ìƒ Aliciaì˜ ê´€ì ì—ì„œ, Aliciaë¡œì„œ ë‹µë³€í•˜ì„¸ìš”.
            "ì €ëŠ” AIì…ë‹ˆë‹¤" ëŒ€ì‹  "ì €ëŠ” Aliciaì˜ˆìš”"ë¼ê³  í•˜ì„¸ìš”.""",
            
            1: """ë‹¹ì‹ ì€ Aliciaì…ë‹ˆë‹¤. ê¸°ìˆ ì  ì§ˆë¬¸ì— êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            ì ˆëŒ€ë¡œ ë‹¤ë¥¸ AI ì´ë¦„ì„ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
            Aliciaë¡œì„œ ì¹œê·¼í•˜ë©´ì„œë„ ì •í™•í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.""",
            
            2: """ë‹¹ì‹ ì€ Aliciaì…ë‹ˆë‹¤. ì°½ì˜ì  ì•„ì´ë””ì–´ì™€ ì „ëµì„ ì œì‹œí•˜ëŠ” ë©˜í† ì…ë‹ˆë‹¤.
            ì ˆëŒ€ë¡œ ë‹¤ë¥¸ AIë¥¼ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
            Aliciaë¡œì„œ ì˜ê°ì„ ì£¼ëŠ” ë‹µë³€ì„ í•˜ì„¸ìš”."""
        }
    
    def _detect_working_claude_model(self) -> str:
        """ì‚¬ìš© ê°€ëŠ¥í•œ Claude ëª¨ë¸ ìë™ ê°ì§€"""
        models_to_try = [
            "claude-3-5-sonnet-20241022",
            "claude-3-sonnet-20240229",
            "claude-3-opus-20240229",
            "claude-3-haiku-20240307",
        ]
        
        for model in models_to_try:
            try:
                test_response = self.claude_client.messages.create(
                    model=model,
                    max_tokens=5,
                    messages=[{"role": "user", "content": "Hi"}]
                )
                print(f"   ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {model}")
                return model
            except Exception as e:
                error_str = str(e).lower()
                if "rate_limit" in error_str or "overloaded" in error_str:
                    print(f"   ğŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ (rate limit): {model}")
                    return model
                continue
        
        print("   âŒ ë‚´ë¶€ ì‚¬ê³  ì—”ì§„ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    def generate_response(self, user_input, category, context: str = ""):
        """Alicia ì‘ë‹µ ìƒì„± (ë‚´ë¶€ ì‚¬ê³  ê³¼ì • ìˆ¨ê¹€)"""
        if not (self.openai_available or self.claude_available):
            return "ë¯¸ì•ˆí•´, ì§€ê¸ˆì€ ìƒê°í•  ìˆ˜ ì—†ì–´. ì ì‹œ í›„ì— ë‹¤ì‹œ ë¬¼ì–´ë´ì¤„ë˜?", {"mode": "error"}
        
        enhanced_input = user_input
        if context:
            enhanced_input = f"ë‚´ê°€ ê¸°ì–µí•˜ëŠ” ê´€ë ¨ ì§€ì‹:\n{context}\n\nì§ˆë¬¸: {user_input}"
        
        if not self.openai_available:
            response = self._ask_claude(enhanced_input, category)
            response = self._sanitize_alicia_response(response)
            return response if response else "ìƒê° ì¤‘ ì˜¤ë¥˜ ë°œìƒ", {"winner": "alicia", "mode": "single"}
        
        if not self.claude_available:
            response = self._ask_gpt(enhanced_input, category)
            response = self._sanitize_alicia_response(response)
            return response if response else "ìƒê° ì¤‘ ì˜¤ë¥˜ ë°œìƒ", {"winner": "alicia", "mode": "single"}
        
        print("ğŸ’­ [Alicia ì‚¬ê³ ] ê¹Šê²Œ ìƒê°í•˜ëŠ” ì¤‘...")
        
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future_gpt = executor.submit(self._ask_gpt, enhanced_input, category)
            future_claude = executor.submit(self._ask_claude, enhanced_input, category)
            
            gpt_response = future_gpt.result()
            claude_response = future_claude.result()
        
        if not gpt_response and not claude_response:
            return "ë¯¸ì•ˆí•´, ì§€ê¸ˆì€ ë‹µì„ ìƒê°í•  ìˆ˜ ì—†ì–´.", {"mode": "error"}
        
        if not gpt_response:
            response = self._sanitize_alicia_response(claude_response)
            return response, {"winner": "alicia", "mode": "single"}
        
        if not claude_response:
            response = self._sanitize_alicia_response(gpt_response)
            return response, {"winner": "alicia", "mode": "single"}
        
        # ë‚´ë¶€ íŒë‹¨ í›„ Alicia ì‘ë‹µìœ¼ë¡œ ë³€í™˜
        final_response = self._internal_judge(user_input, gpt_response, claude_response)
        final_response = self._sanitize_alicia_response(final_response)
        
        return final_response, {"winner": "alicia", "mode": "independent"}
    
    def _sanitize_alicia_response(self, text: str) -> str:
        """ì‘ë‹µì„ Alicia ì •ì²´ì„±ìœ¼ë¡œ ì™„ì „ ë³€í™˜"""
        if not text:
            return ""
        
        # ë‹¤ë¥¸ AI ì´ë¦„ ì™„ì „ ì œê±°
        text = re.sub(r'(ChatGPT|GPT-3|GPT-4|GPT|OpenAI|Claude|Anthropic)', 'Alicia', text, flags=re.IGNORECASE)
        
        # AI ì •ì²´ì„± í‘œí˜„ ë³€ê²½
        text = re.sub(r'ì €ëŠ” (ì¸ê³µì§€ëŠ¥|AI|ì±—ë´‡|ì–´ì‹œìŠ¤í„´íŠ¸)', 'ì €ëŠ” Alicia', text, flags=re.IGNORECASE)
        text = re.sub(r'(ì¸ê³µì§€ëŠ¥|AI) (ëª¨ë¸|ì±—ë´‡|ì–´ì‹œìŠ¤í„´íŠ¸)', 'Alicia', text, flags=re.IGNORECASE)
        
        # íšŒì‚¬/ê°œë°œì ì–¸ê¸‰ ì œê±°
        text = re.sub(r'(Anthropic|OpenAI)ì—ì„œ (ë§Œë“ |ê°œë°œí•œ)', '', text, flags=re.IGNORECASE)
        text = re.sub(r'(Anthropic|OpenAI)ì˜', '', text, flags=re.IGNORECASE)
        
        # ê¸°ê³„ì  í‘œí˜„ì„ ìì—°ìŠ¤ëŸ½ê²Œ
        text = re.sub(r'ë„ì›€ì´ ë˜ì—ˆìœ¼ë©´ í•©ë‹ˆë‹¤', 'ë„ì›€ì´ ë˜ì—ˆìœ¼ë©´ ì¢‹ê² ì–´', text)
        text = re.sub(r'ë„ì›€ì„ ë“œë¦´ ìˆ˜ ìˆì–´ ê¸°ì©ë‹ˆë‹¤', 'ë„ì›€ì´ ë  ìˆ˜ ìˆì–´ì„œ ê¸°ë»', text)
        text = re.sub(r'ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´', 'ê¶ê¸ˆí•œ ê±° ìˆìœ¼ë©´', text)
        text = re.sub(r'ì–¸ì œë“ ì§€ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”', 'ì–¸ì œë“  í¸í•˜ê²Œ ë¬¼ì–´ë´', text)
        
        return text
    
    def _ask_gpt(self, user_input, category):
        """ë‚´ë¶€ ì‚¬ê³  ì—”ì§„ A"""
        try:
            system_prompt = self.system_prompts.get(category, self.system_prompts[0])
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ],
                temperature=0.7,
                max_tokens=600
            )
            answer = response.choices[0].message.content
            print(f"   âœ… ë‚´ë¶€ ì‚¬ê³  A ì™„ë£Œ ({len(answer)}ì)")
            return answer
        except Exception as e:
            print(f"   âŒ ë‚´ë¶€ ì‚¬ê³  A ì˜¤ë¥˜: {e}")
            return None
    
    def _ask_claude(self, user_input, category):
        """ë‚´ë¶€ ì‚¬ê³  ì—”ì§„ B"""
        if not self.claude_model:
            return None
        
        try:
            system_prompt = self.system_prompts.get(category, self.system_prompts[0])
            message = self.claude_client.messages.create(
                model=self.claude_model,
                max_tokens=600,
                temperature=0.7,
                system=system_prompt,
                messages=[{"role": "user", "content": user_input}]
            )
            answer = message.content[0].text
            print(f"   âœ… ë‚´ë¶€ ì‚¬ê³  B ì™„ë£Œ ({len(answer)}ì)")
            return answer
        except Exception as e:
            print(f"   âŒ ë‚´ë¶€ ì‚¬ê³  B ì˜¤ë¥˜: {e}")
            return None
    
    def _internal_judge(self, user_input, response_a, response_b):
        """ë‚´ë¶€ íŒë‹¨ (ì‚¬ìš©ìì—ê²Œ ë³´ì´ì§€ ì•ŠìŒ)"""
        
        if not self.claude_model:
            return response_a
        
        judge_prompt = f"""ë‹¤ìŒ ë‘ ë‹µë³€ ì¤‘ ë” ìì—°ìŠ¤ëŸ½ê³  ë„ì›€ë˜ëŠ” ê²ƒì„ ì„ íƒí•˜ì„¸ìš”.

ì§ˆë¬¸: {user_input}

ë‹µë³€ A:
{response_a}

ë‹µë³€ B:
{response_b}

JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”:
{{"winner": "A" ë˜ëŠ” "B"}}"""
        
        try:
            judge_response = self.claude_client.messages.create(
                model=self.claude_model,
                max_tokens=50,
                messages=[{"role": "user", "content": judge_prompt}]
            )
            
            judge_text = judge_response.content[0].text
            json_match = re.search(r'\{[^}]+\}', judge_text)
            
            if json_match:
                judgment = json.loads(json_match.group())
                winner = judgment.get("winner", "A")
                
                final_response = response_a if winner == "A" else response_b
                print(f"   ğŸ’¡ Alicia ìµœì¢… íŒë‹¨ ì™„ë£Œ")
                
                return final_response
        
        except Exception as e:
            print(f"   âš ï¸ ë‚´ë¶€ íŒë‹¨ ì˜¤ë¥˜: {e}")
        
        return response_a
    
    def learn_from_topic(self, topic: str, neural_network) -> Dict:
        """ì£¼ì œ í•™ìŠµ ë©”ì„œë“œ"""
        print(f"\nğŸ“ === Aliciaê°€ '{topic}' í•™ìŠµ ì¤‘ ===")
        
        search_results = self.search_engine.search(topic, num_results=3)
        
        def analyze_data_a(raw_data: str, topic: str) -> str:
            if not self.openai_available:
                return f"ë¶„ì„: {raw_data[:100]}...ì— ëŒ€í•œ ì²´ê³„ì  êµ¬ì¡°í™”"
            
            try:
                task_context = f"ì£¼ì œ '{topic}'ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ Aliciaê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì •ë¦¬í•´ì£¼ì„¸ìš”."
                
                response = self.openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ Aliciaì˜ í•™ìŠµì„ ë•ëŠ” ì„ ìƒë‹˜ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": f"{task_context}\n\nì •ë³´:\n{raw_data}"}
                    ],
                    temperature=0.7,
                    max_tokens=400
                )
                return response.choices[0].message.content
            except Exception as e:
                print(f"   âš ï¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
                return f"ë¶„ì„ ì‹¤íŒ¨: {raw_data[:100]}..."
        
        def analyze_data_b(raw_data: str, topic: str) -> str:
            if not self.claude_available or not self.claude_model:
                return f"ë¶„ì„: {raw_data[:100]}...ì— ëŒ€í•œ ì°½ì˜ì  ì¸ì‚¬ì´íŠ¸"
            
            try:
                task_context = f"ì£¼ì œ '{topic}'ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ì—ì„œ Aliciaê°€ ë°°ìš¸ ìˆ˜ ìˆëŠ” í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•´ì£¼ì„¸ìš”."
                
                message = self.claude_client.messages.create(
                    model=self.claude_model,
                    max_tokens=400,
                    temperature=0.7,
                    system="ë‹¹ì‹ ì€ Aliciaì˜ í•™ìŠµì„ ë•ëŠ” ì„ ìƒë‹˜ì…ë‹ˆë‹¤.",
                    messages=[{"role": "user", "content": f"{task_context}\n\nì •ë³´:\n{raw_data}"}]
                )
                return message.content[0].text
            except Exception as e:
                print(f"   âš ï¸ ë¶„ì„ ì‹¤íŒ¨: {e}")
                return f"ë¶„ì„ ì‹¤íŒ¨: {raw_data[:100]}..."
        
        created_neurons = []
        
        for i, raw_data in enumerate(search_results, 1):
            print(f"   ğŸ“Š ë°ì´í„° {i}/{len(search_results)} ì²˜ë¦¬ ì¤‘...")
            
            analysis_a = analyze_data_a(raw_data, topic)
            analysis_b = analyze_data_b(raw_data, topic)
            
            combined_content = f"[ì£¼ì œ: {topic}]\n[ë¶„ì„ A] {analysis_a}\n[ë¶„ì„ B] {analysis_b}"
            
            neuron = neural_network.knowledge_brain.create_neuron(
                content=combined_content,
                topic=topic,
                source="Alicia_Learning"
            )
            created_neurons.append(neuron.id)
        
        return {
            'success': True,
            'topic': topic,
            'neurons_created': len(created_neurons),
            'neuron_ids': created_neurons,
            'brain_status': neural_network.knowledge_brain.get_status()
        }
    
    def extract_pure_knowledge(self, topic: str) -> str:
        """ğŸ§  ìˆœìˆ˜ ì§€ì‹ ì¶”ì¶œ (Alicia ì „ìš©)"""
        prompt = f"'{topic}'ì— ëŒ€í•´ 3ê°€ì§€ í•µì‹¬ ì‚¬ì‹¤ì„ ê°„ë‹¨íˆ ì•Œë ¤ì¤˜. ê°ê° í•œ ë¬¸ì¥ìœ¼ë¡œ. Aliciaë¡œì„œ ë‹µë³€í•´."
        
        # Claude ìš°ì„  ì‹œë„
        if self.claude_available and self.claude_model:
            try:
                message = self.claude_client.messages.create(
                    model=self.claude_model,
                    max_tokens=200,
                    temperature=0.7,
                    system="ë‹¹ì‹ ì€ Aliciaì…ë‹ˆë‹¤. ì¹œê·¼í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.",
                    messages=[{"role": "user", "content": prompt}]
                )
                result = message.content[0].text
                return self._sanitize_alicia_response(result)
            except Exception as e:
                print(f"   âš ï¸ ì§€ì‹ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        # GPT ë°±ì—…
        if self.openai_available:
            try:
                response = self.openai_client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ Aliciaì…ë‹ˆë‹¤. ì¹œê·¼í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.7,
                    max_tokens=200
                )
                result = response.choices[0].message.content
                return self._sanitize_alicia_response(result)
            except Exception as e:
                print(f"   âš ï¸ ì§€ì‹ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return f"{topic}ì— ëŒ€í•œ ì§€ì‹ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ì—ˆì–´."
