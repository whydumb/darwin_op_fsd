"""
ìê°€ ì„±ì¥í˜• ì‹ ê²½ë§ + ì§€ì‹ ë‰´ëŸ° ë¸Œë ˆì¸ + ì˜¤í”„ë¼ì¸ ì‚¬ê³  ëŠ¥ë ¥
"""

import numpy as np
import pickle
import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any

class KnowledgeNeuron:
    """ê°œë³„ ì§€ì‹ì„ ì €ì¥í•˜ëŠ” ë‰´ëŸ°"""
    
    def __init__(self, neuron_id: int, content: str, topic: str, 
                 source: str = "Hybrid", confidence: float = 0.8):
        self.id = neuron_id
        self.content = content
        self.topic = topic
        self.source = source
        self.confidence = confidence
        self.connections: Dict[str, float] = {}
        self.activation_count = 0
        self.created_at = datetime.now().isoformat()
        self.last_accessed: Optional[str] = None

    def connect_to(self, other_id: int, weight: float):
        """ë‹¤ë¥¸ ë‰´ëŸ°ê³¼ ì—°ê²° ìƒì„±"""
        self.connections[str(other_id)] = max(0.0, min(1.0, weight))

    def activate(self):
        """ë‰´ëŸ° í™œì„±í™”"""
        self.activation_count += 1
        self.last_accessed = datetime.now().isoformat()

    def to_dict(self) -> Dict:
        return {
            'id': self.id, 'content': self.content, 'topic': self.topic,
            'source': self.source, 'confidence': self.confidence,
            'connections': self.connections, 'activation_count': self.activation_count,
            'created_at': self.created_at, 'last_accessed': self.last_accessed
        }

    @classmethod
    def from_dict(cls, data: Dict) -> 'KnowledgeNeuron':
        neuron = cls(
            neuron_id=data['id'],
            content=data['content'],
            topic=data['topic'],
            source=data.get('source', 'Hybrid'),
            confidence=data.get('confidence', 0.8)
        )
        neuron.connections = data.get('connections', {})
        neuron.activation_count = data.get('activation_count', 0)
        neuron.created_at = data.get('created_at', datetime.now().isoformat())
        neuron.last_accessed = data.get('last_accessed')
        return neuron

class NeuralBrain:
    """ì§€ì‹ ë‰´ëŸ° ë„¤íŠ¸ì›Œí¬ - ì˜¤í”„ë¼ì¸ ì‚¬ê³  ê°€ëŠ¥"""
    
    def __init__(self, storage_path: str = "data/knowledge/neural_brain.json"):
        self.storage_path = storage_path
        self.neurons: Dict[int, KnowledgeNeuron] = {}
        self.next_id = 1
        self.learning_mode = False
        self.growth_events = 0
        self.topics_learned = set()
        
        self._ensure_directory()
        self._load_neurons()

    def _ensure_directory(self):
        os.makedirs(os.path.dirname(self.storage_path), exist_ok=True)

    def _load_neurons(self):
        """ì €ì¥ëœ ë‰´ëŸ°ë“¤ ë¡œë“œ"""
        try:
            if os.path.exists(self.storage_path):
                with open(self.storage_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                for neuron_data in data.get('neurons', []):
                    neuron = KnowledgeNeuron.from_dict(neuron_data)
                    self.neurons[neuron.id] = neuron
                if self.neurons:
                    self.next_id = max(self.neurons.keys()) + 1
                self.growth_events = data.get('growth_events', 0)
                self.topics_learned = set(data.get('topics_learned', []))
                print(f"ğŸ§  ì§€ì‹ ë‰´ëŸ° ë¡œë“œ: {len(self.neurons)}ê°œ")
        except Exception as e:
            print(f"âš ï¸ ì§€ì‹ ë‰´ëŸ° ë¡œë“œ ì‹¤íŒ¨: {e}")

    def _save_neurons(self):
        """ë‰´ëŸ°ë“¤ì„ íŒŒì¼ì— ì €ì¥"""
        try:
            data = {
                'neurons': [n.to_dict() for n in self.neurons.values()],
                'growth_events': self.growth_events,
                'topics_learned': list(self.topics_learned),
                'last_updated': datetime.now().isoformat()
            }
            with open(self.storage_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âŒ ë‰´ëŸ° ì €ì¥ ì‹¤íŒ¨: {e}")

    def toggle_learning_mode(self, enabled: bool):
        """í•™ìŠµ ëª¨ë“œ ON/OFF"""
        self.learning_mode = enabled
        print(f"ğŸ¯ í•™ìŠµ ëª¨ë“œ: {'ON' if enabled else 'OFF'}")

    def calculate_similarity(self, text1: str, text2: str) -> float:
        """í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° (Jaccard Index)"""
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        if not words1 or not words2: return 0.0
        intersection = len(words1 & words2)
        union = len(words1 | words2)
        return intersection / union if union > 0 else 0.0

    def create_neuron(self, content: str, topic: str, source: str = "Hybrid", confidence: float = 0.8) -> KnowledgeNeuron:
        """ìƒˆë¡œìš´ ì§€ì‹ ë‰´ëŸ° ìƒì„±"""
        neuron_id = self.next_id
        self.next_id += 1
        neuron = KnowledgeNeuron(neuron_id, content, topic, source, confidence)
        
        # ê¸°ì¡´ ë‰´ëŸ°ë“¤ê³¼ ì—°ê²° ìƒì„±
        for existing_neuron in self.neurons.values():
            content_sim = self.calculate_similarity(content, existing_neuron.content)
            topic_sim = 0.5 if topic == existing_neuron.topic else 0.0
            total_sim = (content_sim * 0.7 + topic_sim * 0.3)
            if total_sim > 0.2:
                neuron.connect_to(existing_neuron.id, total_sim)
                existing_neuron.connect_to(neuron_id, total_sim)
        
        self.neurons[neuron_id] = neuron
        self.growth_events += 1
        self.topics_learned.add(topic)
        self._save_neurons()
        print(f"   ğŸŒ± ë‰´ëŸ° ìƒì„±: ID-{neuron_id} (ì—°ê²°: {len(neuron.connections)}ê°œ)")
        return neuron

    def query_knowledge(self, query: str, top_k: int = 3) -> List[Tuple[KnowledgeNeuron, float]]:
        """ê´€ë ¨ ì§€ì‹ ê²€ìƒ‰"""
        scored_neurons = []
        for neuron in self.neurons.values():
            content_sim = self.calculate_similarity(query, neuron.content)
            topic_sim = self.calculate_similarity(query, neuron.topic)
            total_score = content_sim * 0.7 + topic_sim * 0.3
            
            if total_score > 0.15:
                neuron.activate()
                scored_neurons.append((neuron, total_score))
        
        scored_neurons.sort(key=lambda x: x[1], reverse=True)
        return scored_neurons[:top_k]

    def get_direct_answer(self, query: str) -> Tuple[Optional[str], float]:
        """ğŸ§  Alicia ì˜¤í”„ë¼ì¸ ì‚¬ê³ : ë‡Œì—ì„œ ì§ì ‘ ë‹µë³€ ì°¾ê¸°"""
        best_matches = self.query_knowledge(query, top_k=3)
        
        if not best_matches:
            return None, 0.0
        
        # ê°€ì¥ ìœ ì‚¬ë„ ë†’ì€ ë‰´ëŸ° ì„ íƒ
        best_neuron, similarity = best_matches[0]
        
        # ì‹ ë¢°ë„ ì„ê³„ê°’ (0.3 ì´ìƒì´ë©´ ì§ì ‘ ë‹µë³€)
        if similarity > 0.3:
            print(f"ğŸ§  [Alicia ë…ë¦½ ì‚¬ê³ ] ë‚´ ê¸°ì–µì—ì„œ ë‹µì„ ì°¾ì•˜ì–´! (ì •í™•ë„: {similarity:.2f})")
            
            # ì—¬ëŸ¬ ê´€ë ¨ ê¸°ì–µ ì¡°í•©
            combined_knowledge = []
            for neuron, score in best_matches[:2]:
                combined_knowledge.append(f"â€¢ {neuron.content[:200]}...")
            
            response = (
                f"ë‚´ê°€ ê¸°ì–µí•˜ê¸°ë¡œëŠ”:\n" + 
                "\n".join(combined_knowledge) + 
                f"\n\nì´ê±´ ë‚´ê°€ ì§ì ‘ ê³µë¶€í•´ì„œ ì•„ëŠ” ë‚´ìš©ì´ì•¼! (ì‹ ë¢°ë„: {similarity:.1%})"
            )
            
            return response, similarity
        
        return None, similarity

    def get_status(self) -> Dict:
        """ë¸Œë ˆì¸ ìƒíƒœ"""
        total_connections = sum(len(n.connections) for n in self.neurons.values())
        return {
            'total_neurons': len(self.neurons),
            'total_connections': total_connections,
            'growth_events': self.growth_events,
            'topics_learned': len(self.topics_learned),
            'learning_mode': self.learning_mode,
            'avg_connections': total_connections / len(self.neurons) if self.neurons else 0
        }

class SelfGrowingNeuralNetwork:
    """ìê°€ ì„±ì¥ ë¶„ë¥˜ ì‹ ê²½ë§ + ì§€ì‹ ë¸Œë ˆì¸"""
    
    def __init__(self, input_size=10, hidden_size=8, output_size=3, learning_rate=0.01):
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.learning_rate = learning_rate
        
        # Xavier ì´ˆê¸°í™”
        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2.0 / input_size)
        self.b1 = np.zeros((1, hidden_size))
        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2.0 / hidden_size)
        self.b2 = np.zeros((1, output_size))
        
        self.training_history = {
            'loss': [], 'accuracy': [], 'epochs': 0,
            'growth_events': [], 'total_conversations': 0, 'instant_growths': 0
        }
        
        self.knowledge_brain = NeuralBrain()
        print(f"ğŸ¤– ì‹ ê²½ë§ ì´ˆê¸°í™”: ë¶„ë¥˜ {hidden_size}ê°œ + ì§€ì‹ {len(self.knowledge_brain.neurons)}ê°œ ë‰´ëŸ°")
    
    def relu(self, x): return np.maximum(0, x)
    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)
    
    def forward(self, X):
        self.z1 = np.dot(X, self.W1) + self.b1
        self.a1 = self.relu(self.z1)
        self.z2 = np.dot(self.a1, self.W2) + self.b2
        self.a2 = self.softmax(self.z2)
        return self.a2
    
    def check_instant_growth(self, features, confidence):
        """ì¦‰ì‹œ ì„±ì¥ í•„ìš”ì„± í™•ì¸"""
        should_grow = False
        reason = ""
        
        if confidence < 0.5:
            should_grow = True
            reason = f"ë§¤ìš° ë‚®ì€ í™•ì‹ ë„ ({confidence*100:.1f}%)"
        elif confidence < 0.7:
            probs = self.forward(features)[0]
            entropy = -np.sum(probs * np.log(probs + 1e-10))
            if entropy > 0.85:
                should_grow = True
                reason = f"ë†’ì€ ë¶ˆí™•ì‹¤ì„± (ì—”íŠ¸ë¡œí”¼: {entropy:.2f})"
        
        if should_grow and self.hidden_size >= 100:
            return False, "ìµœëŒ€ í¬ê¸° ë„ë‹¬"
        
        if should_grow:
            print(f"\nâš¡ ì¦‰ì‹œ ì„±ì¥ íŠ¸ë¦¬ê±°: {reason}")
            self.grow_network(2)
            self.training_history['instant_growths'] += 1
            return True, reason
        return False, "ì„±ì¥ ë¶ˆí•„ìš”"
    
    def grow_network(self, new_neurons=2):
        """ì‹ ê²½ë§ í™•ì¥"""
        print(f"ğŸŒ± ì‹ ê²½ë§ ì„±ì¥: {self.hidden_size} â†’ {self.hidden_size + new_neurons}ê°œ ë‰´ëŸ°")
        old_size = self.hidden_size
        self.hidden_size += new_neurons
        
        new_W1 = np.random.randn(self.input_size, self.hidden_size) * np.sqrt(2.0 / self.input_size)
        new_b1 = np.zeros((1, self.hidden_size))
        new_W2 = np.random.randn(self.hidden_size, self.output_size) * np.sqrt(2.0 / self.hidden_size)
        
        new_W1[:, :old_size] = self.W1
        new_b1[:, :old_size] = self.b1
        new_W2[:old_size, :] = self.W2
        
        self.W1, self.b1, self.W2 = new_W1, new_b1, new_W2
        self.training_history['growth_events'].append({
            'timestamp': datetime.now().isoformat(),
            'old_size': old_size, 'new_size': self.hidden_size,
            'added_neurons': new_neurons, 'trigger': 'instant_growth'
        })
        print("âœ… ì‹ ê²½ë§ í™•ì¥ ì™„ë£Œ! ğŸ§ âœ¨")
    
    def get_contextual_knowledge(self, query: str) -> str:
        """ì§ˆë¬¸ì— ê´€ë ¨ëœ ì§€ì‹ ë‰´ëŸ° ê²€ìƒ‰"""
        related_neurons = self.knowledge_brain.query_knowledge(query, top_k=3)
        if not related_neurons: return ""
        context_parts = []
        for neuron, score in related_neurons:
            context_parts.append(f"[ê´€ë ¨ë„: {score:.2f}] {neuron.content[:200]}")
        return "ğŸ“š ê´€ë ¨ ê¸°ì–µ:\n" + "\n".join(context_parts)
    
    def get_brain_status(self):
        """ì „ì²´ ë‡Œ ìƒíƒœ"""
        base_status = {
            'neurons': self.hidden_size,
            'total_parameters': (self.input_size * self.hidden_size + self.hidden_size * self.output_size),
            'epochs_trained': self.training_history['epochs'],
            'growth_events': len(self.training_history['growth_events']),
            'instant_growths': self.training_history['instant_growths'],
            'conversations': self.training_history['total_conversations']
        }
        knowledge_status = self.knowledge_brain.get_status()
        base_status.update({
            'knowledge_neurons': knowledge_status['total_neurons'],
            'knowledge_connections': knowledge_status['total_connections'],
            'topics_learned': knowledge_status['topics_learned'],
            'learning_mode': knowledge_status['learning_mode']
        })
        return base_status
    
    def save(self, filepath):
        """ëª¨ë¸ ì €ì¥"""
        data = {
            'weights': {'W1': self.W1, 'b1': self.b1, 'W2': self.W2, 'b2': self.b2},
            'config': {'input_size': self.input_size, 'hidden_size': self.hidden_size, 
                       'output_size': self.output_size, 'learning_rate': self.learning_rate},
            'history': self.training_history,
            'metadata': {'saved_at': datetime.now().isoformat(), 'version': '6.0'}
        }
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, 'wb') as f:
            pickle.dump(data, f)
        print(f"ğŸ’¾ ì‹ ê²½ë§ ì €ì¥: {filepath}")
    
    @classmethod
    def load(cls, filepath):
        """ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ"""
        if not os.path.exists(filepath): return None
        try:
            with open(filepath, 'rb') as f:
                data = pickle.load(f)
            nn = cls(**data['config'])
            weights = data['weights']
            nn.W1, nn.b1 = weights['W1'], weights['b1']
            nn.W2, nn.b2 = weights['W2'], weights['b2']
            nn.training_history = data['history']
            print(f"ğŸ“‚ ì‹ ê²½ë§ ë¡œë“œ: {nn.hidden_size}ê°œ ë‰´ëŸ°")
            return nn
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
